\section{視覚に基づいて目的地まで自律移動するシステム}
春山らは，カメラ画像とトポロジカルマップから作成されるシナリオに基づいて，目的地まで自律移動するシステムを構築している．
提案されたシステムは，

1)カメラ画像と目標方向を与えることで,経路を追従するモジュール(以後,経路追従モジュールと呼ぶ)

2)シナリオを分解し,「条件」と「行動」を抽出するモジュール(以後,シナリオモジュールと呼ぶ)

3)カメラ画像から通路の特徴を分類するモジュール(以後,通路分類モジュールと呼ぶ)

の３つのモジュールで構成されており，それぞれについて述べる．
\subsection{経路追従モジュール}
このモジュールは，岡田らの手法から目標方向のデータを加えることで，分岐路で経路を選択し，移動する機能を追加したものである．
ここで目標方向とは，目標とする進行方向（「直進」や「右折」）を表す．
学習時は，カメラ画像とルールベース制御器が出力するヨー方向の角速度，目標方向を 0.2 秒周期でデータセットに加える．
データセットから抽出するバッチサイズや，カメラ画像の解像度は岡田ら手法と同様である．
データセットの収集には藤原らが提案した，データセットに加えるデータの不均衡を改善する手法，学習時に積極的な蛇行する手法を採用する．
\subsection{シナリオモジュール}
\subsection{通路分類モジュール}
このモジュールでは,ニューラルネットワークを用いることで，カメラ画像を入力として，通路の特徴を分類する.
データセットの収集をするために，ロボットをルールベース制御器に基づいて走行させる．
その際に，フレーム数 16 ，画像サイズ 64 × 48の連続したカメラ画像と通路の分類ラベルを１組として，0.125 秒周期でデータセットに加える．
通路の分類ラベルのアノテーションはルールベース制御器から出力されるラベルによって自動的に行う．
データセット内の不均衡を改善するために，クラス間のデータ数によって重み付けを行うコストアプローチを導入している．

実ロボットを用いた実験により，ロボットを目的地まで到達可能か検証されている．
実験では島田ら用いた 50 例のシナリオの中から，７例が用いられており，そのすべてでロボットが目的地へ到達できることが確認されている．