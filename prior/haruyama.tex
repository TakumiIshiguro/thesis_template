\section{視覚に基づいて目的地まで自律移動するシステム}
春山らは，カメラ画像とトポロジカルマップから作成されるシナリオに基づいて，目的地まで自律移動するシステムを構築している．
提案されたシステムは，

1)カメラ画像と目標方向を与えることで,経路を追従するモジュール(以後,経路追従モジュールと呼ぶ)

2)シナリオを分解し,「条件」と「行動」を抽出するモジュール(以後,シナリオモジュールと呼ぶ)

3)カメラ画像から通路の特徴を分類するモジュール(以後,通路分類モジュールと呼ぶ)

の３つのモジュールで構成されており，それぞれについて述べる．
\subsubsection{経路追従モジュール}
このモジュールは，岡田らの手法から目標方向のデータを加えることで，分岐路で経路を選択し，移動する機能を追加したものである．
ここで目標方向とは，目標とする進行方向（「直進」や「右折」）を表す．
学習時は，カメラ画像とルールベース制御器が出力するヨー方向の角速度，目標方向を 0.2 秒周期でデータセットに加える．
データセットから抽出するバッチサイズや，カメラ画像の解像度は岡田ら手法と同様である．
データセットの収集には藤原らが提案した，データセットに加えるデータの不均衡を改善する手法，学習時に積極的な蛇行する手法を採用する．
\subsubsection{シナリオモジュール}
シナリオモジュールは，トポロジカルマップを基に作成されたシナリオから「条件」や「行動」を解釈し，それを分岐路での目標方向に変換して出力する機能を持つ．
トポロジカルマップは，特徴的な通路のノード（青）とそれを繋ぐエッジ（緑）で構成され，ノードにはIDや通路の特徴，接続エッジと方向のデータが含まれている．
シナリオは目的地までの経路を「条件」と「行動」で表現し，例として「三叉路まで直進．右折．突き当たりまで直進．停止」となる．

シナリオの目標方向への変換では，句点ごとに分解し，「条件」と「行動」を抽出して以下の項目に分類する：

通路の特徴（例:「三叉路」「角」）

順番（例:「3つ目の」「2番目の」）

方向（例:「左手に」「右手に」）

行動（例:「右折」「停止」）

例では，「三叉路まで直進」は通路の特徴「三叉路」と行動「直進」に分解される．
この処理を経路全体に対して行い，得られた「行動」を分岐路での目標方向として変換し，経路追従モジュールに渡す．
また，条件の判定には通路分類モジュールを使用する．
\subsubsection{通路分類モジュール}
このモジュールでは,ニューラルネットワークを用いることで，カメラ画像を入力として，通路の特徴を分類する.
データセットの収集をするために，ロボットをルールベース制御器に基づいて走行させる．
その際に，フレーム数 16 ，画像サイズ 64 × 48の連続したカメラ画像と通路の分類ラベルを１組として，0.125 秒周期でデータセットに加える．
通路の分類ラベルのアノテーションはルールベース制御器から出力されるラベルによって自動的に行う．
データセット内の不均衡を改善するために，クラス間のデータ数によって重み付けを行うコストアプローチを導入している．
\subsubsection{実ロボットを用いた実験}
実ロボットを用いた実験により，ロボットを目的地まで到達可能か検証されている．
実験では島田ら用いた 50 例のシナリオの中から，７例が用いられており，そのすべてでロボットが目的地へ到達できることが確認されている．