%!TEX root = ../thesis.tex
\chapter*{概要}
\thispagestyle{empty}
%
\begin{center}
  \scalebox{1.0}{視覚と行動のend-to-end学習により}\\
  \vspace{-1.0zh}
  \scalebox{1.0}{経路追従行動を模倣する手法の提案}\\
  \scalebox{1.0}{-経路選択の成功率向上を意図したネットワークの変更と実験的評価-}\\
\end{center}
\vspace{1.0zh}

本研究室では，移動ロボットのナビゲーション手段を冗長化するために，いくつかの手法を提案している．
岡田らはメトリックマップベースの経路追従行動を end-to-end 学習を用いて模倣学習することで，視覚に基づくナビゲーション手法を提案した．
% 岡田らはメトリックマップに基づく経路追従行動を end-to-end 学習を用いて，視覚を入力とする行動にオンラインで模倣する手法を提案してきた.
春山らは，岡田らの手法に加えて，カメラ画像から通路の種類を分類，シナリオによって目標方向を決定し，経路を選択する機能を追加している．
ここでのシナリオとは，島田らが提案した，「条件」と「行動」に関する単語を組みわせて構成された文章を指す．
% 実ロボットを用いた実験から，構築したシステムにより視覚に基づいて経路を追従して目的地へ到達可能であることを確認した.
春山らは，島田らが作成したシナリオ 50 例から 7 例を選定し，そのすべてで視覚に基づいて経路を追従して目的地まで到達できることを確認している．
選定外のシナリオでは，地面の色が異なる場所や広場を含んでおり，視覚に基づいて経路追従するのがより困難な環境と考えられる．

本論文では，春山らが対象としていないシナリオでも，目的地までカメラ画像のみを入力として経路追従できるか調査する．
% 失敗する場合は要因を調査することで，システムの改良点について考察できるようになる．
はじめに，経路追従の成功率を高めるためのネットワークの変更や新たな学習方法を導入した．
シミュレータを用いた実験によって，これらの手法が経路追従の成功率を上昇させるか検証した．
実ロボットを用いた実験によって，春山らが対象としていないシナリオでも目的地まで移動できることを確認した．

キーワード: 自律移動ロボット end-to-end 学習 ナビゲーション
%
\newpage
%%
\chapter*{abstract}
\thispagestyle{empty}
%
\begin{center}
  \scalebox{1.0}{A proposal for an imitation method of path-tracking behavior}\\
  \vspace{-1zh}
  \scalebox{1.0}{by end-to-end learning of vision and action}
  \scalebox{0.9}{-Modification of network aimed at improving route selection success rate and}\\
  \vspace{-1zh}
  \scalebox{0.9}{its experimental evaluation-}
\end{center}
\vspace{1.0zh}
% In our laboratory, several methods have been proposed to enhance the redundancy of navigation approaches for mobile robots.
% Okada et al. proposed a method that uses end-to-end learning to imitate path-following behavior generated from metric map-based navigation and applies it to vision-based behavior.
% Haruyama et al. extended Okada et al.'s approach by adding functionality to recognize intersection from camera images, determine target directions based on scenarios, and select routes. 
% Here, "scenarios" refer to 50 sentences proposed by Shimada et al., consisting of combinations of words related to "conditions" and "actions."
% Experiments with real robots demonstrated that the constructed system enables destination arrival through vision-based path-following. 
% However, Haruyama et al. showed that only 7 out of the 50 scenarios created by Shimada et al. were successfully autonomously navigated, as the experimental area was partially limited.

% Therefore, this paper investigates whether autonomous navigation to the destination can be achieved using only camera images, even in areas not targeted.
% First, network modifications and new training methods were implemented to improve the success rate of path-following. 
% The effectiveness of these approaches was evaluated through experiments in a simulator. 
% Furthermore, experiments with real robots confirmed that the system could navigate to destinations in scenarios that include unverified areas.

Our laboratory has proposed various methods to enhance the redundancy of mobile robot navigation. 
Okada et al. introduced a vision-based navigation approach by imitating metric map-based path-following behavior using end-to-end learning.
Haruyama et al. extended this method by incorporating corridor classification from camera images and scenario-based path selection. 
The "scenario," as defined by Shimada et al., consists of sentences combining "conditions" and "actions". 
Experiments with a real robot confirmed successful visual-based path following in seven selected scenarios from Shimada et al.'s 50 examples.
Excluded scenarios involved challenging environments such as varying ground colors and open spaces.

In this paper, we investigate whether the robot can follow the path and reach the destination using only camera images, even in scenarios not addressed by Haruyama et al.
First, to improve the success rate of path following, we introduced modifications to the network and new learning methods.
Experiments conducted in a simulator verified whether these methods could enhance the success rate of path following.
Experiments using a real robot confirmed that it could reach the destination even in scenarios not addressed by Haruyama et al.

keywords: autonomouse moblie robot, end-to-end learning, navigation
