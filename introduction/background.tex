%!TEX root = ../thesis.tex

\section{背景}
移動ロボットにおけるナビゲーションとは，目的地までロボットを誘導する制御技術として広く利用されており，物流や，農業，製造業などで活用されている．
一般的には，LiDARやIMU，ホイールエンコーダなどのセンサから得られるデータを用いてオドメトリを計算し，占有格子地図などのメトリックマップに基づいて自己位置推定，経路計画，制御を行うことでロボットを目的地まで誘導する．
一方，カメラ画像と深層学習に基づくナビゲーション技術の研究も進んでいる．

本研究室の岡田らは，従来のナビゲーション行動を視覚を入力として模倣することで，視覚に基づいたナビゲーション手法を提案した．
この手法では，センサとメトリックマップを入力としたルールベース制御器によって生成された角速度とカメラ画像をペアにしてデータセットに加えて学習し，学習後はカメラ画像のみを用いて経路追従行動できることが確認されている．
% この手法では，センサとメトリックマップを入力とした ROS の navigation パッケージによって生成されたナビゲーションの角速度とカメラ画像をペアにして学習し，学習後はカメラ画像のみを用いて経路追従行動できることが確認されている．
% この手法では，一般的な模倣学習が人間のステアリング操作を模倣するのに対し，ナビゲーションシステム自体の行動を模倣する点で特徴的であり，データセットの収集を自動で行うことができる．
% これらの技術の有効性は，シミュレーションおよび実ロボットの実験により検証されており，視覚に基づくナビゲーションで一定の経路追従性能を達成できることが確認されている．

また，春山らはカメラ画像とシナリオに基づいて，任意の目的地まで自律移動するシステムを提案している．
ここでのシナリオとは島田らが提案した，「条件」と「行動」に関する単語を組みわせて構成されている．
この手法では，岡田らの視覚に基づいたナビゲーションに加え，カメラ画像から分岐路を認識，シナリオによって目標方向を決定し，経路を選択する機能を追加している．

\begin{figure}[hbtp]
  \centering
 \includegraphics[keepaspectratio, scale=0.8]
      {images/RaspberryPiMouse.png}
 \caption{Example}
 \label{Fig:Example}
\end{figure}

\newpage
