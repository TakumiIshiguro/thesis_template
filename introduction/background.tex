%!TEX root = ../thesis.tex

\section{背景}
移動ロボットにおけるナビゲーションとは，目的地までロボットを誘導する制御技術として広く利用されており，物流や，農業，製造業などで活用されている．
一般的には，LiDARやIMU，ホイールエンコーダなどのセンサから得られるデータを用いてオドメトリを計算し，占有格子地図などのメトリックマップに基づいて自己位置推定，経路計画，制御を行うことでロボットを目的地まで誘導する．
一方，カメラ画像と深層学習に基づくナビゲーション技術の研究も進んでいる．

本研究室の岡田らは，従来のナビゲーション行動を視覚を入力として模倣することで，視覚に基づいたナビゲーション手法を提案した．
この手法では，センサとメトリックマップを入力としたルールベース制御器によって生成されたヨー方向の角速度とロボットに取り付けたカメラから取得した RGB 画像をペアにしてデータセットに加えて学習し，学習後はカメラ画像のみを用いて経路追従行動できることが確認されている．
% この手法では，センサとメトリックマップを入力とした ROS の navigation パッケージによって生成されたナビゲーションの角速度とカメラ画像をペアにして学習し，学習後はカメラ画像のみを用いて経路追従行動できることが確認されている．
% この手法では，一般的な模倣学習が人間のステアリング操作を模倣するのに対し，ナビゲーションシステム自体の行動を模倣する点で特徴的であり，データセットの収集を自動で行うことができる．
% これらの技術の有効性は，シミュレーションおよび実ロボットの実験により検証されており，視覚に基づくナビゲーションで一定の経路追従性能を達成できることが確認されている．

また，春山らはカメラ画像とシナリオに基づいて，任意の目的地まで自律移動するシステムを提案している．
ここでのシナリオとは島田らが提案した，「条件」と「行動」に関する単語を組みわせて構成されている．
この手法では，岡田らの視覚に基づいたナビゲーションに加え，カメラ画像から分岐路を認識，シナリオによって目標方向を決定し，経路を選択する機能を追加している．
春山らの先行研究では，島田らが提案した５０例のシナリオの中から対象としている７例すべてで自律移動が可能であることを確認している．

先行研究では，島田らが作成したシナリオの中で，以下～～～の区域のみで完結するシナリオを対象としている．
この部分はホワイエと呼ばれるスペースを一部を含むものの，壁や床の色が類似しており，一貫性のある環境といえる．
一方で～～右側を含むシナリオでは先行研究で走行してきたエリアに加えて，ホワイエを通り抜ける必要があることや，地面の色が異なる区域も対象としており，環境が変化するという違いがあり走行が困難な可能性がある．
加えて，このエリアは岡田らが提案した手法で経路追従可能か未検証である．
また，先行研究では対象としたシナリオすべてで自律移動が可能であることが確認されており，失敗の要因は判明していない．

これらの問題点から，新たなエリアを含むシナリオにおいて，目的地までカメラ画像のみで自律移動できるか確認することで，システムの有効性を調査する．
また失敗する場合は要因を調査することで，システムの改良点について考察できるようになる．


\begin{figure}[hbtp]
  \centering
 \includegraphics[keepaspectratio, scale=0.8]
      {images/RaspberryPiMouse.png}
 \caption{Example}
 \label{Fig:Example}
\end{figure}

\newpage
